{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiiir8VjT7XcJdl2cSD5rG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nithya-G-R/GFM/blob/main/merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload the Excel file\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "\n",
        "# 📌 Step 2: Read the Excel file (assuming multiple sheets for different stations)\n",
        "xls = pd.ExcelFile(file_name)\n",
        "\n",
        "# 📌 Step 3: Prepare an empty list to store processed data\n",
        "final_data = []\n",
        "\n",
        "# 📌 Step 4: Process each station's data\n",
        "for sheet_name in xls.sheet_names:\n",
        "    if \"Metadata\" in sheet_name:  # Identify metadata sheets\n",
        "        metadata_df = pd.read_excel(xls, sheet_name=sheet_name, header=None)\n",
        "        data_sheet_name = sheet_name.replace(\"Metadata\", \"Data\")  # Find corresponding data sheet\n",
        "\n",
        "        if data_sheet_name in xls.sheet_names:\n",
        "            data_df = pd.read_excel(xls, sheet_name=data_sheet_name)\n",
        "\n",
        "            # Extract metadata into a dictionary\n",
        "            metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))\n",
        "\n",
        "            # Extract Station Name\n",
        "            station_name = metadata_dict.get(\"Station Name\", \"Unknown\").replace(\" \", \"_\")\n",
        "\n",
        "            # Convert \"Data Time\" to datetime and filter for 2024\n",
        "            data_df[\"Data Time\"] = pd.to_datetime(data_df[\"Data Time\"])\n",
        "            data_df = data_df[data_df[\"Data Time\"].dt.year == 2024]  # Keep only 2024 data\n",
        "\n",
        "            # Extract \"Year-Month\" for grouping\n",
        "            data_df[\"Year-Month\"] = data_df[\"Data Time\"].dt.to_period(\"M\")\n",
        "\n",
        "            # Calculate Monthly Average of \"Data Value\"\n",
        "            monthly_avg_df = data_df.groupby(\"Year-Month\")[\"Data Value\"].mean().reset_index()\n",
        "            monthly_avg_df.rename(columns={\"Data Value\": \"Monthly Average Data Value\"}, inplace=True)\n",
        "\n",
        "            # Select Only Required Metadata Fields\n",
        "            required_columns = [\n",
        "                \"Station Data\", \"Station Code\", \"Station Name\", \"Station Type\", \"Agency Name\",\n",
        "                \"State\", \"District\", \"Tehsil\", \"Data Acquisition\", \"Block\", \"Village\",\n",
        "                \"Latitude\", \"Longitude\", \"Data Available From\", \"Latest Data Available\",\n",
        "                \"Type of Well\", \"Aquifer Type\", \"Well Depth\", \"Unit\"\n",
        "            ]\n",
        "\n",
        "            # Add Required Metadata Fields to DataFrame\n",
        "            for key in required_columns:\n",
        "                monthly_avg_df[key] = metadata_dict.get(key, \"-\")  # Assign metadata or \"-\" if missing\n",
        "\n",
        "            # Append processed data to final list\n",
        "            final_data.append(monthly_avg_df)\n",
        "\n",
        "# 📌 Step 5: Combine all station data into a single DataFrame\n",
        "combined_df = pd.concat(final_data, ignore_index=True)\n",
        "\n",
        "# 📌 Step 6: Save & Download the Final Combined File\n",
        "output_file = \"Monthly_average_ground_water_level_2024_All_Stations.xlsx\"\n",
        "combined_df.to_excel(output_file, index=False)\n",
        "\n",
        "files.download(output_file)  # Download the processed file\n",
        "\n",
        "# Display the first few rows of the combined data\n",
        "combined_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "0M_OEmJVT2Gt",
        "outputId": "b0d30d89-43fe-45b5-9bf6-4903f9f6a461"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ba214d50-eeb6-4cf1-bd33-6e02bd82d91c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ba214d50-eeb6-4cf1-bd33-6e02bd82d91c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Ground Water Level_Yelahanka_2 (1).xlsx to Ground Water Level_Yelahanka_2 (1) (6).xlsx\n",
            "Saving Ground Water Level_Varathur_1 (1).xlsx to Ground Water Level_Varathur_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Thalaghattapurapz_1 (1).xlsx to Ground Water Level_Thalaghattapurapz_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Singasandra_1 (1).xlsx to Ground Water Level_Singasandra_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Nimhans_1 (1).xlsx to Ground Water Level_Nimhans_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Lalbagh garden_1 (1).xlsx to Ground Water Level_Lalbagh garden_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Kannamangala_2 (1).xlsx to Ground Water Level_Kannamangala_2 (1) (6).xlsx\n",
            "Saving Ground Water Level_Jayanagar_1 (1).xlsx to Ground Water Level_Jayanagar_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Indiranagar_1 (1).xlsx to Ground Water Level_Indiranagar_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Indian institute of science_1 (1).xlsx to Ground Water Level_Indian institute of science_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Hesaraghatta pz (1).xlsx to Ground Water Level_Hesaraghatta pz (1) (6).xlsx\n",
            "Saving Ground Water Level_Hebbal2_2 (1).xlsx to Ground Water Level_Hebbal2_2 (1) (6).xlsx\n",
            "Saving Ground Water Level_Dasanapura_1 (1).xlsx to Ground Water Level_Dasanapura_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Cubbon park_1 (1).xlsx to Ground Water Level_Cubbon park_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Bang uni ars ls_1 (1).xlsx to Ground Water Level_Bang uni ars ls_1 (1) (6).xlsx\n",
            "Saving Ground Water Level_Anekal_2 (1).xlsx to Ground Water Level_Anekal_2 (1) (6).xlsx\n",
            "Saving Ground Water Level_Adugodi_1 (1).xlsx to Ground Water Level_Adugodi_1 (1) (7).xlsx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-05f83f90140b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# 📌 Step 5: Combine all station data into a single DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# 📌 Step 6: Save & Download the Final Combined File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_keys_and_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload the Excel file\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "\n",
        "# 📌 Step 2: Read the Excel file (assuming multiple sheets for different stations)\n",
        "xls = pd.ExcelFile(file_name)\n",
        "\n",
        "# 📌 Step 3: Prepare an empty list to store processed data\n",
        "final_data = []\n",
        "\n",
        "# 📌 Step 4: Process each station's data\n",
        "for sheet_name in xls.sheet_names:\n",
        "    if \"Metadata\" in sheet_name:  # Identify metadata sheets\n",
        "        metadata_df = pd.read_excel(xls, sheet_name=sheet_name, header=None)\n",
        "        data_sheet_name = sheet_name.replace(\"Metadata\", \"Data\")  # Find corresponding data sheet\n",
        "\n",
        "        if data_sheet_name in xls.sheet_names:\n",
        "            data_df = pd.read_excel(xls, sheet_name=data_sheet_name)\n",
        "\n",
        "            # Extract metadata into a dictionary\n",
        "            metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))\n",
        "\n",
        "            # Extract Station Name\n",
        "            station_name = metadata_dict.get(\"Station Name\", \"Unknown\").replace(\" \", \"_\")\n",
        "\n",
        "            # Convert \"Data Time\" to datetime and filter for 2024\n",
        "            data_df[\"Data Time\"] = pd.to_datetime(data_df[\"Data Time\"], errors='coerce')\n",
        "            data_df = data_df[data_df[\"Data Time\"].dt.year == 2024]  # Keep only 2024 data\n",
        "\n",
        "            # Check if data is empty after filtering\n",
        "            if data_df.empty:\n",
        "                print(f\"No data for 2024 in {station_name}. Skipping this station.\")\n",
        "                continue  # Skip this station if no data\n",
        "\n",
        "            # Extract \"Year-Month\" for grouping\n",
        "            data_df[\"Year-Month\"] = data_df[\"Data Time\"].dt.to_period(\"M\")\n",
        "\n",
        "            # Calculate Monthly Average of \"Data Value\"\n",
        "            monthly_avg_df = data_df.groupby(\"Year-Month\")[\"Data Value\"].mean().reset_index()\n",
        "            monthly_avg_df.rename(columns={\"Data Value\": \"Monthly Average Data Value\"}, inplace=True)\n",
        "\n",
        "            # Select Only Required Metadata Fields\n",
        "            required_columns = [\n",
        "                \"Station Data\", \"Station Code\", \"Station Name\", \"Station Type\", \"Agency Name\",\n",
        "                \"State\", \"District\", \"Tehsil\", \"Data Acquisition\", \"Block\", \"Village\",\n",
        "                \"Latitude\", \"Longitude\", \"Data Available From\", \"Latest Data Available\",\n",
        "                \"Type of Well\", \"Aquifer Type\", \"Well Depth\", \"Unit\"\n",
        "            ]\n",
        "\n",
        "            # Add Required Metadata Fields to DataFrame\n",
        "            for key in required_columns:\n",
        "                monthly_avg_df[key] = metadata_dict.get(key, \"-\")  # Assign metadata or \"-\" if missing\n",
        "\n",
        "            # Append processed data to final list\n",
        "            final_data.append(monthly_avg_df)\n",
        "        else:\n",
        "            print(f\"No corresponding data sheet for metadata sheet {sheet_name}. Skipping.\")\n",
        "\n",
        "# 📌 Step 5: Combine all station data into a single DataFrame\n",
        "if final_data:\n",
        "    combined_df = pd.concat(final_data, ignore_index=True)\n",
        "\n",
        "    # 📌 Step 6: Save & Download the Final Combined File\n",
        "    output_file = \"Monthly_average_ground_water_level_2024_All_Stations.xlsx\"\n",
        "    combined_df.to_excel(output_file, index=False)\n",
        "\n",
        "    files.download(output_file)  # Download the processed file\n",
        "\n",
        "    # Display the first few rows of the combined data\n",
        "    print(combined_df.head())\n",
        "else:\n",
        "    print(\"No data processed. Please check the input files for missing or incorrect data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "0gijA8B5V8Ki",
        "outputId": "8598c54c-658a-4742-e8d1-5f32b3e5357d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed2fa128-e6b0-4d04-8e11-8eb909914121\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed2fa128-e6b0-4d04-8e11-8eb909914121\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Ground Water Level_Yelahanka_2 (1).xlsx to Ground Water Level_Yelahanka_2 (1) (1).xlsx\n",
            "Saving Ground Water Level_Varathur_1 (1).xlsx to Ground Water Level_Varathur_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Thalaghattapurapz_1 (1).xlsx to Ground Water Level_Thalaghattapurapz_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Singasandra_1 (1).xlsx to Ground Water Level_Singasandra_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Nimhans_1 (1).xlsx to Ground Water Level_Nimhans_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Lalbagh garden_1 (1).xlsx to Ground Water Level_Lalbagh garden_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Kannamangala_2 (1).xlsx to Ground Water Level_Kannamangala_2 (1) (1).xlsx\n",
            "Saving Ground Water Level_Jayanagar_1 (1).xlsx to Ground Water Level_Jayanagar_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Indiranagar_1 (1).xlsx to Ground Water Level_Indiranagar_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Indian institute of science_1 (1).xlsx to Ground Water Level_Indian institute of science_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Hesaraghatta pz (1).xlsx to Ground Water Level_Hesaraghatta pz (1) (1).xlsx\n",
            "Saving Ground Water Level_Hebbal2_2 (1).xlsx to Ground Water Level_Hebbal2_2 (1) (1).xlsx\n",
            "Saving Ground Water Level_Dasanapura_1 (1).xlsx to Ground Water Level_Dasanapura_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Cubbon park_1 (1).xlsx to Ground Water Level_Cubbon park_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Bang uni ars ls_1 (1).xlsx to Ground Water Level_Bang uni ars ls_1 (1) (1).xlsx\n",
            "Saving Ground Water Level_Anekal_2 (1).xlsx to Ground Water Level_Anekal_2 (1) (1).xlsx\n",
            "Saving Ground Water Level_Adugodi_1 (1).xlsx to Ground Water Level_Adugodi_1 (1) (1).xlsx\n",
            "No corresponding data sheet for metadata sheet Metadata - Ground Water Level_Y. Skipping.\n",
            "No data processed. Please check the input files for missing or incorrect data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload multiple Excel files\n",
        "uploaded = files.upload()  # Upload all files at once\n",
        "file_names = list(uploaded.keys())  # Get the list of file names\n",
        "\n",
        "# 📌 Step 2: Loop through each file and process it\n",
        "for file_name in file_names:\n",
        "    # Read both sheets from the Excel file\n",
        "    metadata_df = pd.read_excel(file_name, sheet_name=0, header=None)  # Read Sheet 1 (Metadata)\n",
        "    data_df = pd.read_excel(file_name, sheet_name=1)  # Read Sheet 2 (Time-series data)\n",
        "\n",
        "    # 📌 Step 3: Extract metadata into a dictionary\n",
        "    metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))  # Convert metadata to a dictionary\n",
        "\n",
        "    # 📌 Step 4: Extract Station Name for File Naming\n",
        "    station_name = metadata_dict.get(\"Station Name\", \"Unknown\").replace(\" \", \"_\")  # Replace spaces with underscores\n",
        "\n",
        "    # 📌 Step 5: Convert \"Data Time\" to datetime and filter for 2024\n",
        "    data_df[\"Data Time\"] = pd.to_datetime(data_df[\"Data Time\"])\n",
        "    data_df = data_df[data_df[\"Data Time\"].dt.year == 2024]  # Keep only 2024 data\n",
        "\n",
        "    # 📌 Step 6: Extract \"Year-Month\" for grouping\n",
        "    data_df[\"Year-Month\"] = data_df[\"Data Time\"].dt.to_period(\"M\")\n",
        "\n",
        "    # 📌 Step 7: Calculate Monthly Average of \"Data Value\"\n",
        "    monthly_avg_df = data_df.groupby(\"Year-Month\")[\"Data Value\"].mean().reset_index()\n",
        "    monthly_avg_df.rename(columns={\"Data Value\": \"Monthly Average Data Value\"}, inplace=True)\n",
        "\n",
        "    # 📌 Step 8: Select Only Required Metadata Fields\n",
        "    required_columns = [\n",
        "        \"Station Data\", \"Station Code\", \"Station Name\", \"Station Type\", \"Agency Name\",\n",
        "        \"State\", \"District\", \"Tehsil\", \"Data Acquisition\", \"Block\", \"Village\",\n",
        "        \"Latitude\", \"Longitude\", \"Data Available From\", \"Latest Data Available\",\n",
        "        \"Type of Well\", \"Aquifer Type\", \"Well Depth\", \"Unit\"\n",
        "    ]\n",
        "\n",
        "    # 📌 Step 9: Add Required Metadata Fields to DataFrame\n",
        "    for key in required_columns:\n",
        "        monthly_avg_df[key] = metadata_dict.get(key, \"-\")  # Assign metadata or \"-\" if missing\n",
        "\n",
        "    # 📌 Step 10: Save & Download the Final File with Dynamic Name\n",
        "    output_file = f\"Monthly_average_ground_water_level_2024_{station_name}.xlsx\"\n",
        "    monthly_avg_df.to_excel(output_file, index=False)\n",
        "\n",
        "    files.download(output_file)  # Download the processed file\n",
        "\n",
        "    # Display the processed data for each station\n",
        "    print(f\"Processed data for {station_name}:\")\n",
        "    print(monthly_avg_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hjeZQy2rWwFM",
        "outputId": "804657c9-d2db-46b7-d0a9-0ca3276f365b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7c51a8e9-7b90-4ad5-b011-56b12b5b68d8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7c51a8e9-7b90-4ad5-b011-56b12b5b68d8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Ground Water Level_Yelahanka_2 (1).xlsx to Ground Water Level_Yelahanka_2 (1) (2).xlsx\n",
            "Saving Ground Water Level_Varathur_1 (1).xlsx to Ground Water Level_Varathur_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Thalaghattapurapz_1 (1).xlsx to Ground Water Level_Thalaghattapurapz_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Singasandra_1 (1).xlsx to Ground Water Level_Singasandra_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Nimhans_1 (1).xlsx to Ground Water Level_Nimhans_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Lalbagh garden_1 (1).xlsx to Ground Water Level_Lalbagh garden_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Kannamangala_2 (1).xlsx to Ground Water Level_Kannamangala_2 (1) (2).xlsx\n",
            "Saving Ground Water Level_Jayanagar_1 (1).xlsx to Ground Water Level_Jayanagar_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Indiranagar_1 (1).xlsx to Ground Water Level_Indiranagar_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Indian institute of science_1 (1).xlsx to Ground Water Level_Indian institute of science_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Hesaraghatta pz (1).xlsx to Ground Water Level_Hesaraghatta pz (1) (2).xlsx\n",
            "Saving Ground Water Level_Hebbal2_2 (1).xlsx to Ground Water Level_Hebbal2_2 (1) (2).xlsx\n",
            "Saving Ground Water Level_Dasanapura_1 (1).xlsx to Ground Water Level_Dasanapura_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Cubbon park_1 (1).xlsx to Ground Water Level_Cubbon park_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Bang uni ars ls_1 (1).xlsx to Ground Water Level_Bang uni ars ls_1 (1) (2).xlsx\n",
            "Saving Ground Water Level_Anekal_2 (1).xlsx to Ground Water Level_Anekal_2 (1) (2).xlsx\n",
            "Saving Ground Water Level_Adugodi_1 (1).xlsx to Ground Water Level_Adugodi_1 (1) (2).xlsx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Data Time'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Data Time'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-42be80e25410>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# 📌 Step 5: Convert \"Data Time\" to datetime and filter for 2024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data Time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2024\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Keep only 2024 data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Data Time'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload multiple Excel files\n",
        "uploaded = files.upload()  # Upload all files at once\n",
        "file_names = list(uploaded.keys())  # Get the list of file names\n",
        "\n",
        "# 📌 Step 2: Loop through each file and process it\n",
        "for file_name in file_names:\n",
        "    try:\n",
        "        # Read both sheets from the Excel file\n",
        "        metadata_df = pd.read_excel(file_name, sheet_name=0, header=None)  # Read Sheet 1 (Metadata)\n",
        "        data_df = pd.read_excel(file_name, sheet_name=1)  # Read Sheet 2 (Time-series data)\n",
        "\n",
        "        # 📌 Step 3: Check the columns in the data_df to troubleshoot\n",
        "        print(f\"Columns in {file_name}: {data_df.columns.tolist()}\")  # Print column names to check for discrepancies\n",
        "\n",
        "        # 📌 Step 4: Check if 'Data Time' column exists\n",
        "        if 'Data Time' not in data_df.columns:\n",
        "            print(f\"Warning: 'Data Time' column not found in {file_name}. Skipping this file.\")\n",
        "            continue  # Skip this file if 'Data Time' is missing\n",
        "\n",
        "        # 📌 Step 5: Extract metadata into a dictionary\n",
        "        metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))  # Convert metadata to a dictionary\n",
        "\n",
        "        # 📌 Step 6: Extract Station Name for File Naming\n",
        "        station_name = metadata_dict.get(\"Station Name\", \"Unknown\").replace(\" \", \"_\")  # Replace spaces with underscores\n",
        "\n",
        "        # 📌 Step 7: Convert \"Data Time\" to datetime and filter for 2024\n",
        "        data_df[\"Data Time\"] = pd.to_datetime(data_df[\"Data Time\"])\n",
        "        data_df = data_df[data_df[\"Data Time\"].dt.year == 2024]  # Keep only 2024 data\n",
        "\n",
        "        # 📌 Step 8: Extract \"Year-Month\" for grouping\n",
        "        data_df[\"Year-Month\"] = data_df[\"Data Time\"].dt.to_period(\"M\")\n",
        "\n",
        "        # 📌 Step 9: Calculate Monthly Average of \"Data Value\"\n",
        "        monthly_avg_df = data_df.groupby(\"Year-Month\")[\"Data Value\"].mean().reset_index()\n",
        "        monthly_avg_df.rename(columns={\"Data Value\": \"Monthly Average Data Value\"}, inplace=True)\n",
        "\n",
        "        # 📌 Step 10: Select Only Required Metadata Fields\n",
        "        required_columns = [\n",
        "            \"Station Data\", \"Station Code\", \"Station Name\", \"Station Type\", \"Agency Name\",\n",
        "            \"State\", \"District\", \"Tehsil\", \"Data Acquisition\", \"Block\", \"Village\",\n",
        "            \"Latitude\", \"Longitude\", \"Data Available From\", \"Latest Data Available\",\n",
        "            \"Type of Well\", \"Aquifer Type\", \"Well Depth\", \"Unit\"\n",
        "        ]\n",
        "\n",
        "        # 📌 Step 11: Add Required Metadata Fields to DataFrame\n",
        "        for key in required_columns:\n",
        "            monthly_avg_df[key] = metadata_dict.get(key, \"-\")  # Assign metadata or \"-\" if missing\n",
        "\n",
        "        # 📌 Step 12: Save & Download the Final File with Dynamic Name\n",
        "        output_file = f\"Monthly_average_ground_water_level_2024_{station_name}.xlsx\"\n",
        "        monthly_avg_df.to_excel(output_file, index=False)\n",
        "\n",
        "        files.download(output_file)  # Download the processed file\n",
        "\n",
        "        # Display the processed data for each station\n",
        "        print(f\"Processed data for {station_name}:\")\n",
        "        print(monthly_avg_df.head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sEjUjKjkXZ94",
        "outputId": "47a67fd2-857c-44a1-94d2-2873aafa6e3b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d9a6160-3506-482c-8015-5bfd0652521f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d9a6160-3506-482c-8015-5bfd0652521f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Ground Water Level_Yelahanka_2 (1).xlsx to Ground Water Level_Yelahanka_2 (1) (3).xlsx\n",
            "Saving Ground Water Level_Varathur_1 (1).xlsx to Ground Water Level_Varathur_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Thalaghattapurapz_1 (1).xlsx to Ground Water Level_Thalaghattapurapz_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Singasandra_1 (1).xlsx to Ground Water Level_Singasandra_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Nimhans_1 (1).xlsx to Ground Water Level_Nimhans_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Lalbagh garden_1 (1).xlsx to Ground Water Level_Lalbagh garden_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Kannamangala_2 (1).xlsx to Ground Water Level_Kannamangala_2 (1) (3).xlsx\n",
            "Saving Ground Water Level_Jayanagar_1 (1).xlsx to Ground Water Level_Jayanagar_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Indiranagar_1 (1).xlsx to Ground Water Level_Indiranagar_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Indian institute of science_1 (1).xlsx to Ground Water Level_Indian institute of science_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Hesaraghatta pz (1).xlsx to Ground Water Level_Hesaraghatta pz (1) (3).xlsx\n",
            "Saving Ground Water Level_Hebbal2_2 (1).xlsx to Ground Water Level_Hebbal2_2 (1) (3).xlsx\n",
            "Saving Ground Water Level_Dasanapura_1 (1).xlsx to Ground Water Level_Dasanapura_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Cubbon park_1 (1).xlsx to Ground Water Level_Cubbon park_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Bang uni ars ls_1 (1).xlsx to Ground Water Level_Bang uni ars ls_1 (1) (3).xlsx\n",
            "Saving Ground Water Level_Anekal_2 (1).xlsx to Ground Water Level_Anekal_2 (1) (3).xlsx\n",
            "Saving Ground Water Level_Adugodi_1 (1).xlsx to Ground Water Level_Adugodi_1 (1) (3).xlsx\n",
            "Columns in Ground Water Level_Yelahanka_2 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Yelahanka_2 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Varathur_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Varathur_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Thalaghattapurapz_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Thalaghattapurapz_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Singasandra_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Singasandra_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Nimhans_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Nimhans_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Lalbagh garden_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Lalbagh garden_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Kannamangala_2 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Kannamangala_2 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Jayanagar_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Jayanagar_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Indiranagar_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Indiranagar_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Indian institute of science_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Indian institute of science_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Hesaraghatta pz (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Hesaraghatta pz (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Hebbal2_2 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Hebbal2_2 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Dasanapura_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Dasanapura_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Cubbon park_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Cubbon park_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Bang uni ars ls_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Bang uni ars ls_1 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Anekal_2 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Anekal_2 (1) (3).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Adugodi_1 (1) (3).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Adugodi_1 (1) (3).xlsx. Skipping this file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload multiple Excel files\n",
        "uploaded = files.upload()  # Upload all files at once\n",
        "file_names = list(uploaded.keys())  # Get the list of file names\n",
        "\n",
        "# 📌 Step 2: Loop through each file and process it\n",
        "for file_name in file_names:\n",
        "    try:\n",
        "        # Read both sheets from the Excel file\n",
        "        metadata_df = pd.read_excel(file_name, sheet_name=0, header=None)  # Read Sheet 1 (Metadata)\n",
        "        data_df = pd.read_excel(file_name, sheet_name=1)  # Read Sheet 2 (Time-series data)\n",
        "\n",
        "        # 📌 Step 3: Check the columns in the data_df to troubleshoot\n",
        "        print(f\"Columns in {file_name}: {data_df.columns.tolist()}\")  # Print column names to check for discrepancies\n",
        "\n",
        "        # 📌 Step 4: Check if 'Data Time' column exists in the second sheet (data_df)\n",
        "        if 'Data Time' not in data_df.columns:\n",
        "            print(f\"Warning: 'Data Time' column not found in {file_name}. Skipping this file.\")\n",
        "            continue  # Skip this file if 'Data Time' is missing\n",
        "\n",
        "        # 📌 Step 5: Convert \"Data Time\" to datetime and filter for 2024\n",
        "        data_df[\"Data Time\"] = pd.to_datetime(data_df[\"Data Time\"])\n",
        "        data_df = data_df[data_df[\"Data Time\"].dt.year == 2024]  # Keep only 2024 data\n",
        "\n",
        "        # 📌 Step 6: Extract \"Year-Month\" for grouping\n",
        "        data_df[\"Year-Month\"] = data_df[\"Data Time\"].dt.to_period(\"M\")\n",
        "\n",
        "        # 📌 Step 7: Calculate Monthly Average of \"Data Value\"\n",
        "        monthly_avg_df = data_df.groupby(\"Year-Month\")[\"Data Value\"].mean().reset_index()\n",
        "        monthly_avg_df.rename(columns={\"Data Value\": \"Monthly Average Data Value\"}, inplace=True)\n",
        "\n",
        "        # 📌 Step 8: Select Only Required Metadata Fields\n",
        "        required_columns = [\n",
        "            \"Station Data\", \"Station Code\", \"Station Name\", \"Station Type\", \"Agency Name\",\n",
        "            \"State\", \"District\", \"Tehsil\", \"Data Acquisition\", \"Block\", \"Village\",\n",
        "            \"Latitude\", \"Longitude\", \"Data Available From\", \"Latest Data Available\",\n",
        "            \"Type of Well\", \"Aquifer Type\", \"Well Depth\", \"Unit\"\n",
        "        ]\n",
        "\n",
        "        # 📌 Step 9: Add Required Metadata Fields to DataFrame\n",
        "        metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))  # Convert metadata to a dictionary\n",
        "        for key in required_columns:\n",
        "            monthly_avg_df[key] = metadata_dict.get(key, \"-\")  # Assign metadata or \"-\" if missing\n",
        "\n",
        "        # 📌 Step 10: Save & Download the Final File with Dynamic Name\n",
        "        station_name = metadata_dict.get(\"Station Name\", \"Unknown\").replace(\" \", \"_\")  # Replace spaces with underscores\n",
        "        output_file = f\"Monthly_average_ground_water_level_2024_{station_name}.xlsx\"\n",
        "        monthly_avg_df.to_excel(output_file, index=False)\n",
        "\n",
        "        files.download(output_file)  # Download the processed file\n",
        "\n",
        "        # Display the processed data for each station\n",
        "        print(f\"Processed data for {station_name}:\")\n",
        "        print(monthly_avg_df.head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "izZKEk_3ZF6T",
        "outputId": "eefb5944-3c57-48b4-f838-d2baf0e6512e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5fec64bc-634f-49e6-8b4a-e56076e2bf7f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5fec64bc-634f-49e6-8b4a-e56076e2bf7f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Ground Water Level_Yelahanka_2 (1).xlsx to Ground Water Level_Yelahanka_2 (1) (5).xlsx\n",
            "Saving Ground Water Level_Varathur_1 (1).xlsx to Ground Water Level_Varathur_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Thalaghattapurapz_1 (1).xlsx to Ground Water Level_Thalaghattapurapz_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Singasandra_1 (1).xlsx to Ground Water Level_Singasandra_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Nimhans_1 (1).xlsx to Ground Water Level_Nimhans_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Lalbagh garden_1 (1).xlsx to Ground Water Level_Lalbagh garden_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Kannamangala_2 (1).xlsx to Ground Water Level_Kannamangala_2 (1) (5).xlsx\n",
            "Saving Ground Water Level_Jayanagar_1 (1).xlsx to Ground Water Level_Jayanagar_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Indiranagar_1 (1).xlsx to Ground Water Level_Indiranagar_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Indian institute of science_1 (1).xlsx to Ground Water Level_Indian institute of science_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Hesaraghatta pz (1).xlsx to Ground Water Level_Hesaraghatta pz (1) (5).xlsx\n",
            "Saving Ground Water Level_Hebbal2_2 (1).xlsx to Ground Water Level_Hebbal2_2 (1) (5).xlsx\n",
            "Saving Ground Water Level_Dasanapura_1 (1).xlsx to Ground Water Level_Dasanapura_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Cubbon park_1 (1).xlsx to Ground Water Level_Cubbon park_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Bang uni ars ls_1 (1).xlsx to Ground Water Level_Bang uni ars ls_1 (1) (5).xlsx\n",
            "Saving Ground Water Level_Anekal_2 (1).xlsx to Ground Water Level_Anekal_2 (1) (5).xlsx\n",
            "Saving Ground Water Level_Adugodi_1 (1).xlsx to Ground Water Level_Adugodi_1 (1) (5).xlsx\n",
            "Columns in Ground Water Level_Yelahanka_2 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Yelahanka_2 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Varathur_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Varathur_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Thalaghattapurapz_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Thalaghattapurapz_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Singasandra_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Singasandra_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Nimhans_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Nimhans_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Lalbagh garden_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Lalbagh garden_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Kannamangala_2 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Kannamangala_2 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Jayanagar_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Jayanagar_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Indiranagar_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Indiranagar_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Indian institute of science_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Indian institute of science_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Hesaraghatta pz (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Hesaraghatta pz (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Hebbal2_2 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Hebbal2_2 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Dasanapura_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Dasanapura_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Cubbon park_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Cubbon park_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Bang uni ars ls_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Bang uni ars ls_1 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Anekal_2 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Anekal_2 (1) (5).xlsx. Skipping this file.\n",
            "Columns in Ground Water Level_Adugodi_1 (1) (5).xlsx: ['Unnamed: 0', 'Unnamed: 1', 'National Water Informatics Centre', 'Unnamed: 3', 'Unnamed: 4']\n",
            "Warning: 'Data Time' column not found in Ground Water Level_Adugodi_1 (1) (5).xlsx. Skipping this file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload the Excel file\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "\n",
        "# 📌 Step 2: Read both sheets from the Excel file\n",
        "metadata_df = pd.read_excel(file_name, sheet_name=0, header=None)  # Read Sheet 1 (Metadata)\n",
        "data_df = pd.read_excel(file_name, sheet_name=1)  # Read Sheet 2 (Time-series data)\n",
        "\n",
        "# 📌 Step 3: Extract metadata into a dictionary\n",
        "metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))  # Convert metadata to a dictionary\n",
        "\n",
        "# 📌 Step 4: Extract Station Name for File Naming\n",
        "station_name = metadata_dict.get(\"Station Name\", \"Unknown\").replace(\" \", \"_\")  # Replace spaces with underscores\n",
        "\n",
        "# 📌 Step 5: Convert \"Data Time\" to datetime and filter for 2024\n",
        "data_df[\"Data Time\"] = pd.to_datetime(data_df[\"Data Time\"])\n",
        "data_df = data_df[data_df[\"Data Time\"].dt.year == 2024]  # Keep only 2024 data\n",
        "\n",
        "# 📌 Step 6: Extract \"Year-Month\" for grouping\n",
        "data_df[\"Year-Month\"] = data_df[\"Data Time\"].dt.to_period(\"M\")\n",
        "\n",
        "# 📌 Step 7: Calculate Monthly Average of \"Data Value\"\n",
        "monthly_avg_df = data_df.groupby(\"Year-Month\")[\"Data Value\"].mean().reset_index()\n",
        "monthly_avg_df.rename(columns={\"Data Value\": \"Monthly Average Data Value\"}, inplace=True)\n",
        "\n",
        "# 📌 Step 8: Add Metadata to Each Row\n",
        "for key, value in metadata_dict.items():\n",
        "    monthly_avg_df[key] = value  # Assign metadata to each row\n",
        "\n",
        "# 📌 Step 9: Save & Download the Final File with Dynamic Name\n",
        "output_file = f\"Monthly_average_ground_water_level_2024_{station_name}.xlsx\"\n",
        "monthly_avg_df.to_excel(output_file, index=False)\n",
        "\n",
        "files.download(output_file)  # Download the processed file\n",
        "\n",
        "# Display the processed data\n",
        "monthly_avg_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "Vx01w8OWZ_bq",
        "outputId": "c1a77450-b2d0-43da-c97f-0c0990c5eb40"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6b1c1a5-6813-4115-b310-019d57fa5bbe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c6b1c1a5-6813-4115-b310-019d57fa5bbe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Ground Water Level_Adugodi_1 (1).xlsx to Ground Water Level_Adugodi_1 (1) (6).xlsx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Data Time'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Data Time'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5dee432da96b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 📌 Step 5: Convert \"Data Time\" to datetime and filter for 2024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data Time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2024\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Keep only 2024 data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Data Time'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Get the absolute paths of all Excel files in the current directory\n",
        "all_excel_files = glob.glob(\"*.xlsx\")\n",
        "\n",
        "# Read all Excel files at once\n",
        "df = pd.concat(pd.read_excel(excel_file) for excel_file in all_excel_files)\n",
        "\n",
        "# Save the combined DataFrame to a new Excel file\n",
        "df.to_excel(\"combined_data.xlsx\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4i23S8gzkoi3",
        "outputId": "8de4bb0d-87d0-4870-bf8e-5be90b0ef11d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'glob' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-567d6d81e26b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get the absolute paths of all Excel files in the current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mall_excel_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Read all Excel files at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload all processed Excel files\n",
        "uploaded = files.upload()  # Upload all 17 files at once\n",
        "file_names = list(uploaded.keys())  # Get the list of uploaded file names\n",
        "\n",
        "# 📌 Step 2: Create an empty list to store DataFrames\n",
        "merged_data = []\n",
        "\n",
        "# 📌 Step 3: Loop through each file and read the data\n",
        "for file_name in file_names:\n",
        "    try:\n",
        "        # Read the processed monthly average file\n",
        "        df = pd.read_excel(file_name)\n",
        "\n",
        "        # Add a column to indicate the station name (Extract from filename)\n",
        "        station_name = file_name.replace(\".xlsx\", \"\").replace(\"Monthly_average_ground_water_level_2024_\", \"\")\n",
        "        df[\"Station Name\"] = station_name  # Add station name column\n",
        "\n",
        "        # Append to the merged list\n",
        "        merged_data.append(df)\n",
        "\n",
        "        print(f\"✅ Merged: {file_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error processing file {file_name}: {e}\")\n",
        "\n",
        "# 📌 Step 4: Merge all DataFrames into one\n",
        "if merged_data:\n",
        "    final_df = pd.concat(merged_data, ignore_index=True)\n",
        "\n",
        "    # 📌 Step 5: Save & Download the Final Merged File\n",
        "    output_file = \"Final_Merged_Monthly_Average_Ground_Water_Level_2024.xlsx\"\n",
        "    final_df.to_excel(output_file, index=False)\n",
        "\n",
        "    files.download(output_file)  # Download the final merged file\n",
        "\n",
        "    print(\"✅ Merging complete! File saved as:\", output_file)\n",
        "    print(final_df.head())  # Display first few rows of the merged data\n",
        "else:\n",
        "    print(\"⚠️ No valid data to merge. Please check your files.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5XtDCLJMlmNk",
        "outputId": "2b24f567-7e23-4011-c79b-a558446f82ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-363b0a12-4b09-46ac-bae1-928f204e32f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-363b0a12-4b09-46ac-bae1-928f204e32f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Monthly_average_ground_water_level_2024_Yelahanka_2.xlsx to Monthly_average_ground_water_level_2024_Yelahanka_2.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Varathur_1.xlsx to Monthly_average_ground_water_level_2024_Varathur_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Thalaghattapurapz_1.xlsx to Monthly_average_ground_water_level_2024_Thalaghattapurapz_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Singasandra_1.xlsx to Monthly_average_ground_water_level_2024_Singasandra_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Nimhans_1.xlsx to Monthly_average_ground_water_level_2024_Nimhans_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Lalbagh_garden_1.xlsx to Monthly_average_ground_water_level_2024_Lalbagh_garden_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Kannamangala_2.xlsx to Monthly_average_ground_water_level_2024_Kannamangala_2.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Jayanagar_1.xlsx to Monthly_average_ground_water_level_2024_Jayanagar_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Indiranagar_1.xlsx to Monthly_average_ground_water_level_2024_Indiranagar_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Indian_institute_of_science_1.xlsx to Monthly_average_ground_water_level_2024_Indian_institute_of_science_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Hesaraghatta_pz.xlsx to Monthly_average_ground_water_level_2024_Hesaraghatta_pz.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Hebbal2_2.xlsx to Monthly_average_ground_water_level_2024_Hebbal2_2.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Dasanapura_1.xlsx to Monthly_average_ground_water_level_2024_Dasanapura_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Cubbon_park_1.xlsx to Monthly_average_ground_water_level_2024_Cubbon_park_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Bang_uni_ars_ls_1.xlsx to Monthly_average_ground_water_level_2024_Bang_uni_ars_ls_1.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Anekal_2.xlsx to Monthly_average_ground_water_level_2024_Anekal_2.xlsx\n",
            "Saving Monthly_average_ground_water_level_2024_Adugodi_1 (4).xlsx to Monthly_average_ground_water_level_2024_Adugodi_1 (4).xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Yelahanka_2.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Varathur_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Thalaghattapurapz_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Singasandra_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Nimhans_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Lalbagh_garden_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Kannamangala_2.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Jayanagar_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Indiranagar_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Indian_institute_of_science_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Hesaraghatta_pz.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Hebbal2_2.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Dasanapura_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Cubbon_park_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Bang_uni_ars_ls_1.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Anekal_2.xlsx\n",
            "✅ Merged: Monthly_average_ground_water_level_2024_Adugodi_1 (4).xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_16530028-9053-42d5-898b-67a95d230e7b\", \"Final_Merged_Monthly_Average_Ground_Water_Level_2024.xlsx\", 26172)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Merging complete! File saved as: Final_Merged_Monthly_Average_Ground_Water_Level_2024.xlsx\n",
            "  Year-Month  Monthly Average Data Value  Unnamed: 2 Station Data  \\\n",
            "0    2024-01                  -15.577177         NaN  Data Values   \n",
            "1    2024-02                  -16.758455         NaN  Data Values   \n",
            "2    2024-03                  -17.629346         NaN  Data Values   \n",
            "3    2024-04                  -18.171518         NaN  Data Values   \n",
            "4    2024-05                  -18.233558         NaN  Data Values   \n",
            "\n",
            "  Station Code Station Name  Station Type Agency Name      State  \\\n",
            "0   CGWBNG0034  Yelahanka_2  Ground water        Cgwb  Karnataka   \n",
            "1   CGWBNG0034  Yelahanka_2  Ground water        Cgwb  Karnataka   \n",
            "2   CGWBNG0034  Yelahanka_2  Ground water        Cgwb  Karnataka   \n",
            "3   CGWBNG0034  Yelahanka_2  Ground water        Cgwb  Karnataka   \n",
            "4   CGWBNG0034  Yelahanka_2  Ground water        Cgwb  Karnataka   \n",
            "\n",
            "          District  ...  Data Available From Latest  Data Available  \\\n",
            "0  Bangalore urban  ...  2023-06-20 00:00:00    2025-01-16 00:00:00   \n",
            "1  Bangalore urban  ...  2023-06-20 00:00:00    2025-01-16 00:00:00   \n",
            "2  Bangalore urban  ...  2023-06-20 00:00:00    2025-01-16 00:00:00   \n",
            "3  Bangalore urban  ...  2023-06-20 00:00:00    2025-01-16 00:00:00   \n",
            "4  Bangalore urban  ...  2023-06-20 00:00:00    2025-01-16 00:00:00   \n",
            "\n",
            "  Type of Well   Aquifer Type  Well Depth  Unit  \\\n",
            "0    Bore well  Semi-confined        54.0     m   \n",
            "1    Bore well  Semi-confined        54.0     m   \n",
            "2    Bore well  Semi-confined        54.0     m   \n",
            "3    Bore well  Semi-confined        54.0     m   \n",
            "4    Bore well  Semi-confined        54.0     m   \n",
            "\n",
            "  This sheet is downloaded from www.indiawris.gov.in. Disclaimer:  \\\n",
            "0                                                NaN          NaN   \n",
            "1                                                NaN          NaN   \n",
            "2                                                NaN          NaN   \n",
            "3                                                NaN          NaN   \n",
            "4                                                NaN          NaN   \n",
            "\n",
            "  The water and allied data published by National Water Information Centre (NWIC) is sourced from various data producing agencies.   \\\n",
            "0                                                NaN                                                                                  \n",
            "1                                                NaN                                                                                  \n",
            "2                                                NaN                                                                                  \n",
            "3                                                NaN                                                                                  \n",
            "4                                                NaN                                                                                  \n",
            "\n",
            "  Any further information and clarification regarding the data may be sought by the user from the respective data producing agency.  \n",
            "0                                                NaN                                                                                 \n",
            "1                                                NaN                                                                                 \n",
            "2                                                NaN                                                                                 \n",
            "3                                                NaN                                                                                 \n",
            "4                                                NaN                                                                                 \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    }
  ]
}